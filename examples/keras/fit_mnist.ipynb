{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.split(os.getcwd())[0])[0])\n",
    "config_filepath = os.path.join(os.getcwd(),\"config/fit_config_mnist.json\")\n",
    "notebook_filepath = os.path.join(os.getcwd(),\"fit_mnist.ipynb\")\n",
    "import uuid\n",
    "import json\n",
    "import datetime\n",
    "import getpass\n",
    "\n",
    "from mercury_ml.common import tasks\n",
    "from mercury_ml.common import utils\n",
    "from mercury_ml.common import containers as common_containers\n",
    "from mercury_ml.keras import containers as keras_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4().hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load config file and update placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_referenced_json_config(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config[\"meta_info\"], {\n",
    "    \"session_id\": session_id,\n",
    "    \"model_purpose\": config[\"meta_info\"][\"model_purpose\"],\n",
    "    \"config_filepath\": config_filepath,\n",
    "    \"notebook_filepath\": notebook_filepath\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config, config[\"meta_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "`get_and_log`, or basically `getattr`, is used to read out function names from the config file.\n",
    "This is necesarry because different functions are used in different context. E.g. there are different functions for Keras than for H2O. Or for reading images instead of reading arrays from .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_log(container, class_name, params):\n",
    "    provider = getattr(container, class_name)(**params)\n",
    "    print(\"{}.{}\".format(container.__name__, class_name))\n",
    "    print(\"params: \", json.dumps(params, indent=2))\n",
    "    return provider\n",
    "\n",
    "def get_and_log(container, function_name):\n",
    "    provider = getattr(container, function_name)\n",
    "    print(\"{}.{}\".format(container.__name__, function_name))\n",
    "    return provider\n",
    "def maybe_transform(data_bunch, pre_execution_parameters):\n",
    "    if pre_execution_parameters:\n",
    "        return data_bunch.transform(**pre_execution_parameters)\n",
    "    else:\n",
    "        return data_bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and convert MNIST Images\n",
    "If the images for training do not exist, download them and save them as .png images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config[\"exec\"][\"read_source_data\"][\"params\"][\"train_params\"][\"iterator_params\"][\"directory\"]):\n",
    "    from load_mnist import download_and_convert_mnist \n",
    "    download_and_convert_mnist(config[\"meta_info\"][\"data_bunch_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "First read out from the config file which file input\n",
    "Second read the data from source into a generator, ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_source_data_set = get_and_log(common_containers.SourceReaders, config[\"init\"][\"read_source_data\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_source = tasks.read_train_valid_test_data_bunch(read_source_data_set,**config[\"exec\"][\"read_source_data\"][\"params\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are parameters speifed for pre_execution_transformation, the data has to be transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_fit = maybe_transform(data_bunch_source, config[\"exec\"][\"fit\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load keras functions from config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_optimizer = get_and_log(keras_containers.OptimizerFetchers, \n",
    "                           config[\"init\"][\"get_optimizer\"][\"name\"])\n",
    "get_loss_function = get_and_log(keras_containers.LossFunctionFetchers, \n",
    "                                config[\"init\"][\"get_loss_function\"][\"name\"])\n",
    "compile_model = get_and_log(keras_containers.ModelCompilers, \n",
    "                            config[\"init\"][\"compile_model\"][\"name\"])\n",
    "fit = get_and_log(keras_containers.ModelFitters, config[\"init\"][\"fit\"][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(config[\"exec\"][\"read_source_data\"][\"params\"][\"train_params\"][\"iterator_params\"][\"color_mode\"]==\"grayscale\"):\n",
    "    color_size = 1\n",
    "elif(config[\"exec\"][\"read_source_data\"][\"params\"][\"train_params\"][\"iterator_params\"][\"color_mode\"]==\"RGBA\"):\n",
    "    color_size = 4\n",
    "else: #color_mode is RGB\n",
    "    color_size = 3\n",
    "input_shape = (config[\"exec\"][\"define_model\"][\"params\"][\"input_size\"][0],config[\"exec\"][\"define_model\"][\"params\"][\"input_size\"][1],color_size)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # converting 2D array into fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(rate=config[\"exec\"][\"define_model\"][\"params\"][\"dropout_rate\"], seed=12345))\n",
    "model.add(Dense(config[\"exec\"][\"define_model\"][\"params\"][\"nb_classes\"],activation=tf.nn.softmax))\n",
    "\n",
    "model = compile_model(model=model,\n",
    "                      optimizer=get_optimizer(**config[\"exec\"][\"get_optimizer\"][\"params\"]),\n",
    "                      loss=get_loss_function(**config[\"exec\"][\"get_loss_function\"][\"params\"]),\n",
    "                      **config[\"exec\"][\"compile_model\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks for monitoring training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "for callback in config[\"init\"][\"callbacks\"]:\n",
    "    callbacks = callbacks + [get_and_log(keras_containers.CallBacks, callback[\"name\"])(callback[\"params\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(model = model,\n",
    "            data_bunch = data_bunch_fit,\n",
    "            callbacks = callbacks,\n",
    "            **config[\"exec\"][\"fit\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_dict = {\n",
    "    save_model_function_name: get_and_log(keras_containers.ModelSavers, save_model_function_name) for save_model_function_name in config[\"init\"][\"save_model\"][\"names\"]\n",
    "}\n",
    "for model_format, save_model in save_model_dict.items():\n",
    "    \n",
    "    tasks.store_model(save_model=save_model,\n",
    "                      model=model,\n",
    "                      copy_from_local_to_remote = get_and_log(common_containers.ArtifactCopiers, config[\"init\"][\"copy_from_local_to_remote\"][\"name\"]),\n",
    "                      **config[\"exec\"][\"save_model\"][model_format]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = get_and_log(keras_containers.ModelEvaluators, config[\"init\"][\"evaluate\"][\"name\"])\n",
    "predict = get_and_log(keras_containers.PredictionFunctions, config[\"init\"][\"predict\"][\"name\"])\n",
    "custom_label_metrics_dict = {\n",
    "    custom_label_metric_name: get_and_log(common_containers.CustomLabelMetrics, custom_label_metric_name) for custom_label_metric_name in config[\"init\"][\"custom_label_metrics\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_metrics = maybe_transform(data_bunch_fit, config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))\n",
    "data_bunch_predict = maybe_transform(data_bunch_metrics, config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "for data_set_name in config[\"exec\"][\"predict\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_predict, data_set_name)\n",
    "    data_set.predictions = predict(model=model, data_set=data_set, **config[\"exec\"][\"predict\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_metrics = maybe_transform(data_bunch_fit, config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))\n",
    "metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_metrics, data_set_name)\n",
    "    metrics[data_set_name] = evaluate(model, data_set, **config[\"exec\"][\"evaluate\"][\"params\"])\n",
    "print(json.dumps(metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_bunch_custom_metrics = maybe_transform(data_bunch_predict, \n",
    "                                            config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))\n",
    "custom_label_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_label_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_label_metrics[data_set_name] = tasks.evaluate_label_metrics(data_set, custom_label_metrics_dict)\n",
    "print(json.dumps(custom_label_metrics, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
