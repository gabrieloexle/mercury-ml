{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.split(os.getcwd())[0])[0])\n",
    "config_filepath = os.path.join(os.getcwd(),\"config/fit_config_array.json\")\n",
    "notebook_filepath = os.path.join(os.getcwd(),\"fit.ipynb\")\n",
    "import uuid\n",
    "import json\n",
    "import datetime\n",
    "import getpass\n",
    "\n",
    "from mercury_ml.common import tasks\n",
    "from mercury_ml.common import utils\n",
    "from mercury_ml.common import containers as common_containers\n",
    "from mercury_ml.keras import containers as keras_containers\n",
    "\n",
    "# ## Helpers\n",
    "#\n",
    "# These functions will help with the flow of this particular notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_bunch(data_bunch):\n",
    "\n",
    "    for data_set_name, data_set in data_bunch.__dict__.items():\n",
    "        print(\"{} <{}>\".format(data_set_name, type(data_set).__name__))\n",
    "        for data_wrapper_name, data_wrapper in data_set.__dict__.items():\n",
    "            print(\"  {} <{}>\".format(data_wrapper_name, type(data_wrapper).__name__))\n",
    "        print()\n",
    "        \n",
    "def maybe_transform(data_bunch, pre_execution_parameters):\n",
    "    if pre_execution_parameters:\n",
    "        return data_bunch.transform(**pre_execution_parameters)\n",
    "    else:\n",
    "        return data_bunch\n",
    "        \n",
    "def print_dict(d):\n",
    "    print(json.dumps(d, indent=2))\n",
    "\n",
    "def get_installed_packages():\n",
    "    import pip\n",
    "    try:\n",
    "        from pip._internal.operations import freeze\n",
    "    except ImportError:  # pip < 10.0\n",
    "        from pip.operations import freeze\n",
    "\n",
    "    packages = []\n",
    "    for p in freeze.freeze():\n",
    "        packages.append(p)\n",
    "\n",
    "    return packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_referenced_json_config(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"global_references\": {\n",
      "    \"number_of_classes\": 3,\n",
      "    \"batch_size\": 2,\n",
      "    \"labels\": [\n",
      "      0,\n",
      "      1,\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_array\",\n",
      "    \"session_id\": \"{session_id}\",\n",
      "    \"model_object_name\": \"{model_purpose}__{session_id}\",\n",
      "    \"data_bunch_name\": \"array_123\",\n",
      "    \"notebook_filepath\": \"{notebook_filepath}\",\n",
      "    \"config_filepath\": \"{config_filepath}\"\n",
      "  },\n",
      "  \"init\": {\n",
      "    \"read_source_data\": {\n",
      "      \"name\": \"read_disk_pandas\"\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"name\": \"define_mlp_simple\"\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"name\": \"get_keras_optimizer\"\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"name\": \"get_keras_loss\"\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"name\": \"compile_model\"\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"name\": \"fit\"\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"names\": [\n",
      "        \"save_hdf5\",\n",
      "        \"save_tensorflow_serving_predict_signature_def\"\n",
      "      ]\n",
      "    },\n",
      "    \"copy_from_local_to_remote\": {\n",
      "      \"name\": \"copy_from_disk_to_disk\"\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"name\": \"evaluate\"\n",
      "    },\n",
      "    \"callbacks\": [\n",
      "      {\n",
      "        \"name\": \"early_stopping\",\n",
      "        \"params\": {\n",
      "          \"patience\": 5,\n",
      "          \"monitor\": \"val_loss\",\n",
      "          \"min_delta\": 0.001\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"model_checkpoint\",\n",
      "        \"params\": {\n",
      "          \"filepath\": \"./example_results/local/{session_id}/model_checkpoint/last_best_model.h5\",\n",
      "          \"save_best_only\": true\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"predict\": {\n",
      "      \"name\": \"predict\"\n",
      "    },\n",
      "    \"custom_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_auc\",\n",
      "        \"evaluate_numpy_micro_auc\"\n",
      "      ]\n",
      "    },\n",
      "    \"custom_label_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_accuracy\",\n",
      "        \"evaluate_numpy_confusion_matrix\"\n",
      "      ]\n",
      "    },\n",
      "    \"store_prediction_artifact_locally\": {\n",
      "      \"name\": \"store_pandas_pickle\"\n",
      "    },\n",
      "    \"store_artifact_locally\": {\n",
      "      \"name\": \"store_dict_json\"\n",
      "    }\n",
      "  },\n",
      "  \"exec\": {\n",
      "    \"read_source_data\": {\n",
      "      \"params\": {\n",
      "        \"train_params\": {\n",
      "          \"path\": \"./example_data/{data_bunch_name}/train.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"valid_params\": {\n",
      "          \"path\": \"./example_data/{data_bunch_name}/valid.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"test_params\": {\n",
      "          \"path\": \"./example_data/{data_bunch_name}/test.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"params\": {\n",
      "        \"nb_classes\": 3,\n",
      "        \"nb_features\": 3,\n",
      "        \"dense_activation\": \"relu\",\n",
      "        \"final_activation\": \"softmax\"\n",
      "      }\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"params\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"optimizer_params\": {\n",
      "          \"lr\": 0.0001\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"params\": {\n",
      "        \"loss_name\": \"categorical_crossentropy\"\n",
      "      }\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"params\": {\n",
      "        \"metrics\": [\n",
      "          \"acc\"\n",
      "        ],\n",
      "        \"weighted_metrics\": null,\n",
      "        \"loss_weights\": null,\n",
      "        \"sample_weight_mode\": null,\n",
      "        \"target_tensors\": null\n",
      "      }\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"params\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"epochs\": 10\n",
      "      },\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"train\",\n",
      "          \"valid\",\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"transform_then_slice\": true,\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"full_data_wrapper_params\": {},\n",
      "          \"data_wrapper_names\": [\n",
      "            \"features\",\n",
      "            \"targets\",\n",
      "            \"index\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"predict\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"save_hdf5\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/models\",\n",
      "        \"filename\": \"{model_object_name}__hdf5\",\n",
      "        \"extension\": \".h5\",\n",
      "        \"overwrite_remote\": true\n",
      "      },\n",
      "      \"save_tensorflow_serving_predict_signature_def\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/models\",\n",
      "        \"filename\": \"{model_object_name}__tf_serving_predict\",\n",
      "        \"temp_base_dir\": \"c:/tf_serving/_tmp_model/{model_object_name}__tf_serving_predict\",\n",
      "        \"extension\": \".zip\",\n",
      "        \"overwrite_remote\": true,\n",
      "        \"do_save_labels_txt\": true,\n",
      "        \"input_name\": \"input\",\n",
      "        \"output_name\": \"output\",\n",
      "        \"labels_list\": [\n",
      "          \"cat\",\n",
      "          \"dog\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"evaluate_custom_metrics\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"evaluate_custom_label_metrics\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_session\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/session\",\n",
      "        \"filename\": \"session\"\n",
      "      }\n",
      "    },\n",
      "    \"save_session_artifacts\": {\n",
      "      \"artifacts\": [\n",
      "        {\n",
      "          \"artifact_path\": \"{config_filepath}\",\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/session\"\n",
      "        },\n",
      "        {\n",
      "          \"artifact_path\": \"{notebook_filepath}\",\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/session\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"save_formatted_config\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/session\",\n",
      "        \"filename\": \"config_formatted\"\n",
      "      }\n",
      "    },\n",
      "    \"prepare_predictions_for_storage\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"pandas\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"predictions\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"predictions\",\n",
      "          \"new_data_wrapper_name\": \"predictions_for_storage\"\n",
      "        },\n",
      "        \"targets\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"targets\",\n",
      "          \"new_data_wrapper_name\": \"targets_for_storage\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_predictions\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/{session_id}/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/{session_id}/predictions/test\",\n",
      "            \"filename\": \"{model_object_name}__test__predictions\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_targets\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"targets_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/{session_id}/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/{session_id}/predictions/test\",\n",
      "            \"filename\": \"{model_object_name}__test__targets\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__keras_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__custom_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_label_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__custom_label_metrics\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4().hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b02a1c74a09642639b46f7d0457d5e2e\n"
     ]
    }
   ],
   "source": [
    "print(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update config\n",
    "\n",
    "The function `utils.recursively_update_config(config, string_formatting_dict)` allows us to use string formatting to replace placeholder strings with acctual values.\n",
    "\n",
    "for example: \n",
    "\n",
    "```python\n",
    ">>> config = {\"some_value\": \"some_string_{some_placeholder}\"}\n",
    ">>> string_formatting_dict = {\"some_placeholder\": \"ABC\"}\n",
    ">>> utils.recursively_update_config(config, string_formatting_dict)\n",
    ">>> print(config)\n",
    "{\"some_value\": \"some_string_ABC}\"}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First update `config[\"meta_info\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config[\"meta_info\"], {\n",
    "    \"session_id\": session_id,\n",
    "    \"model_purpose\": config[\"meta_info\"][\"model_purpose\"],\n",
    "    \"config_filepath\": config_filepath,\n",
    "    \"notebook_filepath\": notebook_filepath\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `config[\"meta_info\"]` to update the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config, config[\"meta_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"global_references\": {\n",
      "    \"number_of_classes\": 3,\n",
      "    \"batch_size\": 2,\n",
      "    \"labels\": [\n",
      "      0,\n",
      "      1,\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_array\",\n",
      "    \"session_id\": \"b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"model_object_name\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"data_bunch_name\": \"array_123\",\n",
      "    \"notebook_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "    \"config_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\"\n",
      "  },\n",
      "  \"init\": {\n",
      "    \"read_source_data\": {\n",
      "      \"name\": \"read_disk_pandas\"\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"name\": \"define_mlp_simple\"\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"name\": \"get_keras_optimizer\"\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"name\": \"get_keras_loss\"\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"name\": \"compile_model\"\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"name\": \"fit\"\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"names\": [\n",
      "        \"save_hdf5\",\n",
      "        \"save_tensorflow_serving_predict_signature_def\"\n",
      "      ]\n",
      "    },\n",
      "    \"copy_from_local_to_remote\": {\n",
      "      \"name\": \"copy_from_disk_to_disk\"\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"name\": \"evaluate\"\n",
      "    },\n",
      "    \"callbacks\": [\n",
      "      {\n",
      "        \"name\": \"early_stopping\",\n",
      "        \"params\": {\n",
      "          \"patience\": 5,\n",
      "          \"monitor\": \"val_loss\",\n",
      "          \"min_delta\": 0.001\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"model_checkpoint\",\n",
      "        \"params\": {\n",
      "          \"filepath\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/model_checkpoint/last_best_model.h5\",\n",
      "          \"save_best_only\": true\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"predict\": {\n",
      "      \"name\": \"predict\"\n",
      "    },\n",
      "    \"custom_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_auc\",\n",
      "        \"evaluate_numpy_micro_auc\"\n",
      "      ]\n",
      "    },\n",
      "    \"custom_label_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_accuracy\",\n",
      "        \"evaluate_numpy_confusion_matrix\"\n",
      "      ]\n",
      "    },\n",
      "    \"store_prediction_artifact_locally\": {\n",
      "      \"name\": \"store_pandas_pickle\"\n",
      "    },\n",
      "    \"store_artifact_locally\": {\n",
      "      \"name\": \"store_dict_json\"\n",
      "    }\n",
      "  },\n",
      "  \"exec\": {\n",
      "    \"read_source_data\": {\n",
      "      \"params\": {\n",
      "        \"train_params\": {\n",
      "          \"path\": \"./example_data/array_123/train.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"valid_params\": {\n",
      "          \"path\": \"./example_data/array_123/valid.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"test_params\": {\n",
      "          \"path\": \"./example_data/array_123/test.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"params\": {\n",
      "        \"nb_classes\": 3,\n",
      "        \"nb_features\": 3,\n",
      "        \"dense_activation\": \"relu\",\n",
      "        \"final_activation\": \"softmax\"\n",
      "      }\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"params\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"optimizer_params\": {\n",
      "          \"lr\": 0.0001\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"params\": {\n",
      "        \"loss_name\": \"categorical_crossentropy\"\n",
      "      }\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"params\": {\n",
      "        \"metrics\": [\n",
      "          \"acc\"\n",
      "        ],\n",
      "        \"weighted_metrics\": null,\n",
      "        \"loss_weights\": null,\n",
      "        \"sample_weight_mode\": null,\n",
      "        \"target_tensors\": null\n",
      "      }\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"params\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"epochs\": 10\n",
      "      },\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"train\",\n",
      "          \"valid\",\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"transform_then_slice\": true,\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"full_data_wrapper_params\": {},\n",
      "          \"data_wrapper_names\": [\n",
      "            \"features\",\n",
      "            \"targets\",\n",
      "            \"index\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"predict\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"save_hdf5\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__hdf5\",\n",
      "        \"extension\": \".h5\",\n",
      "        \"overwrite_remote\": true\n",
      "      },\n",
      "      \"save_tensorflow_serving_predict_signature_def\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "        \"temp_base_dir\": \"c:/tf_serving/_tmp_model/test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "        \"extension\": \".zip\",\n",
      "        \"overwrite_remote\": true,\n",
      "        \"do_save_labels_txt\": true,\n",
      "        \"input_name\": \"input\",\n",
      "        \"output_name\": \"output\",\n",
      "        \"labels_list\": [\n",
      "          \"cat\",\n",
      "          \"dog\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"evaluate_custom_metrics\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"evaluate_custom_label_metrics\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_session\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"filename\": \"session\"\n",
      "      }\n",
      "    },\n",
      "    \"save_session_artifacts\": {\n",
      "      \"artifacts\": [\n",
      "        {\n",
      "          \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\",\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "        },\n",
      "        {\n",
      "          \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"save_formatted_config\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"filename\": \"config_formatted\"\n",
      "      }\n",
      "    },\n",
      "    \"prepare_predictions_for_storage\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"pandas\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"predictions\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"predictions\",\n",
      "          \"new_data_wrapper_name\": \"predictions_for_storage\"\n",
      "        },\n",
      "        \"targets\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"targets\",\n",
      "          \"new_data_wrapper_name\": \"targets_for_storage\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_predictions\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__predictions\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_targets\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"targets_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__targets\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__keras_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_label_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_label_metrics\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "Create a small dictionary with the session information. This will later be stored as a dictionary artifact with all the key run infomration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = {\n",
    "    \"time_stamp\": datetime.datetime.utcnow().isoformat()[:-3] + \"Z\",\n",
    "    \"run_by\": getpass.getuser(),\n",
    "    \"meta_info\": config[\"meta_info\"],\n",
    "    \"installed_packages\": get_installed_packages()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session info\n",
      "{\n",
      "  \"time_stamp\": \"2019-03-07T14:39:22.427Z\",\n",
      "  \"run_by\": \"karl.schriek\",\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_array\",\n",
      "    \"session_id\": \"b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"model_object_name\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"data_bunch_name\": \"array_123\",\n",
      "    \"notebook_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "    \"config_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\"\n",
      "  },\n",
      "  \"installed_packages\": [\n",
      "    \"absl-py==0.7.0\",\n",
      "    \"astor==0.7.1\",\n",
      "    \"attrs==19.1.0\",\n",
      "    \"backcall==0.1.0\",\n",
      "    \"bleach==3.1.0\",\n",
      "    \"certifi==2018.11.29\",\n",
      "    \"chardet==3.0.4\",\n",
      "    \"colorama==0.4.1\",\n",
      "    \"decorator==4.3.2\",\n",
      "    \"defusedxml==0.5.0\",\n",
      "    \"docutils==0.14\",\n",
      "    \"entrypoints==0.3\",\n",
      "    \"gast==0.2.2\",\n",
      "    \"grpcio==1.19.0\",\n",
      "    \"h5py==2.9.0\",\n",
      "    \"idna==2.8\",\n",
      "    \"ipykernel==5.1.0\",\n",
      "    \"ipython==7.3.0\",\n",
      "    \"ipython-genutils==0.2.0\",\n",
      "    \"ipywidgets==7.4.2\",\n",
      "    \"jedi==0.13.3\",\n",
      "    \"Jinja2==2.10\",\n",
      "    \"jsonref==0.2\",\n",
      "    \"jsonschema==3.0.1\",\n",
      "    \"jupyter==1.0.0\",\n",
      "    \"jupyter-client==5.2.4\",\n",
      "    \"jupyter-console==6.0.0\",\n",
      "    \"jupyter-core==4.4.0\",\n",
      "    \"jupytext==1.0.2\",\n",
      "    \"Keras==2.2.4\",\n",
      "    \"Keras-Applications==1.0.7\",\n",
      "    \"Keras-Preprocessing==1.0.9\",\n",
      "    \"Markdown==3.0.1\",\n",
      "    \"MarkupSafe==1.1.1\",\n",
      "    \"mercury-ml==0.1.3\",\n",
      "    \"mistune==0.8.4\",\n",
      "    \"mock==2.0.0\",\n",
      "    \"nbconvert==5.4.1\",\n",
      "    \"nbformat==4.4.0\",\n",
      "    \"notebook==5.7.5\",\n",
      "    \"numpy==1.16.2\",\n",
      "    \"pandas==0.24.1\",\n",
      "    \"pandocfilters==1.4.2\",\n",
      "    \"parso==0.3.4\",\n",
      "    \"pbr==5.1.3\",\n",
      "    \"pickleshare==0.7.5\",\n",
      "    \"pip==9.0.1\",\n",
      "    \"pkginfo==1.5.0.1\",\n",
      "    \"prometheus-client==0.6.0\",\n",
      "    \"prompt-toolkit==2.0.9\",\n",
      "    \"protobuf==3.7.0\",\n",
      "    \"Pygments==2.3.1\",\n",
      "    \"pyrsistent==0.14.11\",\n",
      "    \"python-dateutil==2.8.0\",\n",
      "    \"pytz==2018.9\",\n",
      "    \"pywinpty==0.5.5\",\n",
      "    \"PyYAML==3.13\",\n",
      "    \"pyzmq==18.0.1\",\n",
      "    \"qtconsole==4.4.3\",\n",
      "    \"readme-renderer==24.0\",\n",
      "    \"requests==2.21.0\",\n",
      "    \"requests-toolbelt==0.9.1\",\n",
      "    \"scikit-learn==0.20.3\",\n",
      "    \"scipy==1.2.1\",\n",
      "    \"Send2Trash==1.5.0\",\n",
      "    \"setuptools==40.7.1\",\n",
      "    \"six==1.12.0\",\n",
      "    \"sklearn==0.0\",\n",
      "    \"tensorboard==1.13.1\",\n",
      "    \"tensorflow==1.13.1\",\n",
      "    \"tensorflow-estimator==1.13.0\",\n",
      "    \"tensorflow-serving-api==1.12.0\",\n",
      "    \"termcolor==1.1.0\",\n",
      "    \"terminado==0.8.1\",\n",
      "    \"testfixtures==6.6.0\",\n",
      "    \"testpath==0.4.2\",\n",
      "    \"tornado==6.0.1\",\n",
      "    \"tqdm==4.30.0\",\n",
      "    \"traitlets==4.3.2\",\n",
      "    \"twine==1.12.1\",\n",
      "    \"urllib3==1.24.1\",\n",
      "    \"wcwidth==0.1.7\",\n",
      "    \"webencodings==0.5.1\",\n",
      "    \"Werkzeug==0.14.1\",\n",
      "    \"wheel==0.32.3\",\n",
      "    \"widgetsnbextension==3.4.2\",\n",
      "    \"wincertstore==0.2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session info\")\n",
    "print(json.dumps(session, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Theseare the functions or classes we will be using in this workflow. We get / instatiate them all at the beginning using parameters under `config[\"initialization\"]`.\n",
    "\n",
    "Here we use mainly use `getattr` to fetch them via the `containers` module based on a string input in the config file. Providers could however also be fetched directly. The following three methods are all equivalent:\n",
    "\n",
    "```python\n",
    "# 1. (what we are using in this notebook)\n",
    "from ml_workflow.common import containers as common_containers\n",
    "source_reader=getattr(common_containers.SourceReaders, \"read_pandas_data_set\")\n",
    "\n",
    "# 2. \n",
    "from ml_workflow.common import containers as common_containers\n",
    "source_reader=common_containers.SourceReaders.read_pandas_data_set\n",
    "\n",
    "# 3.\n",
    "from ml_workflow.common.providers.source_reading import read_pandas_data_set\n",
    "source_reader=read_pandas_data_set\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "These helper functions will create instantiate class providers (`create_and_log`) or fetch function providers (`get_and_log`) based on the parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_log(container, class_name, params):\n",
    "    provider = getattr(container, class_name)(**params)\n",
    "    print(\"{}.{}\".format(container.__name__, class_name))\n",
    "    print(\"params: \", json.dumps(params, indent=2))\n",
    "    return provider\n",
    "\n",
    "def get_and_log(container, function_name):\n",
    "    provider = getattr(container, function_name)\n",
    "    print(\"{}.{}\".format(container.__name__, function_name))\n",
    "    return provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common\n",
    "\n",
    "These are providers that are universally relevant, regardless of which Machine Learning engine is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalArtifactStorers.store_dict_json\n"
     ]
    }
   ],
   "source": [
    "# a function for storing dictionary artifacts to local disk\n",
    "store_artifact_locally = get_and_log(common_containers.LocalArtifactStorers,\n",
    "                                     config[\"init\"][\"store_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalArtifactStorers.store_pandas_pickle\n"
     ]
    }
   ],
   "source": [
    "# a function for storing data-frame-like artifacts to local disk\n",
    "store_prediction_artifact_locally = get_and_log(common_containers.LocalArtifactStorers,\n",
    "                                                config[\"init\"][\"store_prediction_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArtifactCopiers.copy_from_disk_to_disk\n"
     ]
    }
   ],
   "source": [
    "# a function for copy artifacts from local disk to a remote store\n",
    "copy_from_local_to_remote = get_and_log(common_containers.ArtifactCopiers, config[\"init\"][\"copy_from_local_to_remote\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SourceReaders.read_disk_pandas\n"
     ]
    }
   ],
   "source": [
    "# a function for reading source data. When called it will return an instance of type DataBunch \n",
    "read_source_data_set = get_and_log(common_containers.SourceReaders, config[\"init\"][\"read_source_data\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomMetrics.evaluate_numpy_auc\n",
      "CustomMetrics.evaluate_numpy_micro_auc\n"
     ]
    }
   ],
   "source": [
    "# a dictionary of functions that calculate custom metrics\n",
    "custom_metrics_dict = {\n",
    "    custom_metric_name: get_and_log(common_containers.CustomMetrics, custom_metric_name) for custom_metric_name in config[\"init\"][\"custom_metrics\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLabelMetrics.evaluate_numpy_accuracy\n",
      "CustomLabelMetrics.evaluate_numpy_confusion_matrix\n"
     ]
    }
   ],
   "source": [
    "# a dictionary of functions that calculate custom label metrics\n",
    "custom_label_metrics_dict = {\n",
    "    custom_label_metric_name: get_and_log(common_containers.CustomLabelMetrics, custom_label_metric_name) for custom_label_metric_name in config[\"init\"][\"custom_label_metrics\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDefinitions.define_mlp_simple\n"
     ]
    }
   ],
   "source": [
    "# a function that returns an uncompiled keras model\n",
    "define_model = get_and_log(keras_containers.ModelDefinitions, \n",
    "                           config[\"init\"][\"define_model\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossFunctionFetchers.get_keras_loss\n"
     ]
    }
   ],
   "source": [
    "# a function that returns a keras loss function\n",
    "get_loss_function = get_and_log(keras_containers.LossFunctionFetchers, \n",
    "                                config[\"init\"][\"get_loss_function\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizerFetchers.get_keras_optimizer\n"
     ]
    }
   ],
   "source": [
    "# a function that returns a keras optimizer\n",
    "get_optimizer = get_and_log(keras_containers.OptimizerFetchers, \n",
    "                           config[\"init\"][\"get_optimizer\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCompilers.compile_model\n"
     ]
    }
   ],
   "source": [
    "# a function that returns a compiled keras model\n",
    "compile_model = get_and_log(keras_containers.ModelCompilers, \n",
    "                            config[\"init\"][\"compile_model\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelFitters.fit\n"
     ]
    }
   ],
   "source": [
    "# a function that fits a compiled keras model\n",
    "fit = get_and_log(keras_containers.ModelFitters, config[\"init\"][\"fit\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallBacks.early_stopping\n",
      "CallBacks.model_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# a list of functions that serve as callback when fitting a keras model\n",
    "callbacks = []\n",
    "for callback in config[\"init\"][\"callbacks\"]:\n",
    "    callbacks = callbacks + [get_and_log(keras_containers.CallBacks, callback[\"name\"])(callback[\"params\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEvaluators.evaluate\n"
     ]
    }
   ],
   "source": [
    "# a function for evaluating keras metrics\n",
    "evaluate = get_and_log(keras_containers.ModelEvaluators, config[\"init\"][\"evaluate\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSavers.save_hdf5\n",
      "ModelSavers.save_tensorflow_serving_predict_signature_def\n"
     ]
    }
   ],
   "source": [
    "# a dictionary of functions that save keras models in various formats\n",
    "save_model_dict = {\n",
    "    save_model_function_name: get_and_log(keras_containers.ModelSavers, save_model_function_name) for save_model_function_name in config[\"init\"][\"save_model\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionFunctions.predict\n"
     ]
    }
   ],
   "source": [
    "# a function that predictions using a keras model\n",
    "predict = get_and_log(keras_containers.PredictionFunctions, config[\"init\"][\"predict\"][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Here we use the providers defined above to execute various tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data read using following parameters: \n",
      "\n",
      "{\n",
      "  \"train_params\": {\n",
      "    \"path\": \"./example_data/array_123/train.csv\",\n",
      "    \"input_format\": \".csv\",\n",
      "    \"full_data_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\",\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\",\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ],\n",
      "    \"index_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\"\n",
      "    ],\n",
      "    \"features_columns\": [\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\"\n",
      "    ],\n",
      "    \"targets_columns\": [\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ]\n",
      "  },\n",
      "  \"valid_params\": {\n",
      "    \"path\": \"./example_data/array_123/valid.csv\",\n",
      "    \"input_format\": \".csv\",\n",
      "    \"full_data_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\",\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\",\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ],\n",
      "    \"index_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\"\n",
      "    ],\n",
      "    \"features_columns\": [\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\"\n",
      "    ],\n",
      "    \"targets_columns\": [\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ]\n",
      "  },\n",
      "  \"test_params\": {\n",
      "    \"path\": \"./example_data/array_123/test.csv\",\n",
      "    \"input_format\": \".csv\",\n",
      "    \"full_data_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\",\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\",\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ],\n",
      "    \"index_columns\": [\n",
      "      \"ID\",\n",
      "      \"ID2\"\n",
      "    ],\n",
      "    \"features_columns\": [\n",
      "      \"field1_num\",\n",
      "      \"field2_num\",\n",
      "      \"field3_num\"\n",
      "    ],\n",
      "    \"targets_columns\": [\n",
      "      \"field4_target\",\n",
      "      \"field5_target\",\n",
      "      \"field6_target\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_bunch_source = tasks.read_train_valid_test_data_bunch(read_source_data_set,**config[\"exec\"][\"read_source_data\"][\"params\"] )\n",
    "print(\"Source data read using following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"read_source_data\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data_bunch consists of: \n",
      "\n",
      "train <DataSet>\n",
      "  full_data <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  features <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "\n",
      "valid <DataSet>\n",
      "  full_data <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  features <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "\n",
      "test <DataSet>\n",
      "  full_data <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  features <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Read data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\karl.schriek\\appdata\\local\\conda\\conda\\envs\\mercury_ml_training\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = define_model(**config[\"exec\"][\"define_model\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defintion used: define_mlp_simple \n",
      "\n",
      "Model parameters used: \n",
      "{\n",
      "  \"nb_classes\": 3,\n",
      "  \"nb_features\": 3,\n",
      "  \"dense_activation\": \"relu\",\n",
      "  \"final_activation\": \"softmax\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model defintion used:\", config[\"init\"][\"define_model\"][\"name\"], \"\\n\")\n",
    "print(\"Model parameters used: \")\n",
    "print_dict(config[\"exec\"][\"define_model\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(**config[\"exec\"][\"get_optimizer\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer fetched with following parameters: \n",
      "{\n",
      "  \"optimizer_name\": \"adam\",\n",
      "  \"optimizer_params\": {\n",
      "    \"lr\": 0.0001\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizer fetched with following parameters: \")\n",
    "print_dict(config[\"exec\"][\"get_optimizer\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss_function(**config[\"exec\"][\"get_loss_function\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function fetched with following parameters: \n",
      "{\n",
      "  \"optimizer_name\": \"adam\",\n",
      "  \"optimizer_params\": {\n",
      "    \"lr\": 0.0001\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss function fetched with following parameters: \")\n",
    "print_dict(config[\"exec\"][\"get_optimizer\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(model=model,\n",
    "                      optimizer=optimizer,\n",
    "                      loss=loss,\n",
    "                      **config[\"exec\"][\"compile_model\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_set_names\": [\n",
      "    \"train\",\n",
      "    \"valid\",\n",
      "    \"test\"\n",
      "  ],\n",
      "  \"transform_then_slice\": true,\n",
      "  \"params\": {\n",
      "    \"transform_to\": \"numpy\",\n",
      "    \"full_data_wrapper_params\": {},\n",
      "    \"data_wrapper_names\": [\n",
      "      \"features\",\n",
      "      \"targets\",\n",
      "      \"index\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_bunch_fit = maybe_transform(data_bunch_source, config[\"exec\"][\"fit\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"fit\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "train <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "valid <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "test <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\karl.schriek\\appdata\\local\\conda\\conda\\envs\\mercury_ml_training\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 20 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 1.9814 - acc: 0.5000 - val_loss: 1.9712 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 848us/step - loss: 1.9620 - acc: 0.5000 - val_loss: 1.9558 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 748us/step - loss: 1.9470 - acc: 0.5000 - val_loss: 1.9376 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 947us/step - loss: 1.9305 - acc: 0.5000 - val_loss: 1.9195 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9130 - acc: 0.5000 - val_loss: 1.9021 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 748us/step - loss: 1.8972 - acc: 0.5000 - val_loss: 1.8851 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 848us/step - loss: 1.8790 - acc: 0.5000 - val_loss: 1.8693 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 698us/step - loss: 1.8635 - acc: 0.5000 - val_loss: 1.8534 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 798us/step - loss: 1.8479 - acc: 0.5000 - val_loss: 1.8374 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 947us/step - loss: 1.8307 - acc: 0.5000 - val_loss: 1.8229 - val_acc: 0.5000\n",
      "return_best_model set to False. Returning model from last epoch\n"
     ]
    }
   ],
   "source": [
    "model = fit(model = model,\n",
    "            data_bunch = data_bunch_fit,\n",
    "            callbacks = callbacks,\n",
    "            **config[\"exec\"][\"fit\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual trained epochs: 10\n"
     ]
    }
   ],
   "source": [
    "actual_epochs=len(model.history.history[\"acc\"])\n",
    "print(\"Actual trained epochs: {}\".format(actual_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history: \n",
      "{\n",
      "  \"val_loss\": [\n",
      "    1.9712057530879974,\n",
      "    1.9557744354009627,\n",
      "    1.9376160383224488,\n",
      "    1.919517183303833,\n",
      "    1.9021284461021424,\n",
      "    1.8850532650947571,\n",
      "    1.869289606809616,\n",
      "    1.8533921867609024,\n",
      "    1.8374166697263719,\n",
      "    1.8228549987077713\n",
      "  ],\n",
      "  \"val_acc\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"loss\": [\n",
      "    1.9814257144927978,\n",
      "    1.9620218321681022,\n",
      "    1.9469922117888927,\n",
      "    1.930476374924183,\n",
      "    1.9130401119589806,\n",
      "    1.8972187697887422,\n",
      "    1.8790043979883193,\n",
      "    1.8635313004255294,\n",
      "    1.8478590726852417,\n",
      "    1.830685842037201\n",
      "  ],\n",
      "  \"acc\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training history: \")\n",
    "print_dict(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "session[\"actual_epochs\"]=actual_epochs\n",
    "session[\"history\"]=model.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save (formatted) config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, config,\n",
    "                      **config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config stored with following parameters\n",
      "{\n",
      "  \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "  \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "  \"filename\": \"config_formatted\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Config stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, session,\n",
    "                      **config[\"exec\"][\"save_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session dictionary stored with following parameters\n",
      "{\n",
      "  \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "  \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "  \"filename\": \"session\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session dictionary stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"global_references\": {\n",
      "    \"number_of_classes\": 3,\n",
      "    \"batch_size\": 2,\n",
      "    \"labels\": [\n",
      "      0,\n",
      "      1,\n",
      "      2\n",
      "    ]\n",
      "  },\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_array\",\n",
      "    \"session_id\": \"b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"model_object_name\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e\",\n",
      "    \"data_bunch_name\": \"array_123\",\n",
      "    \"notebook_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "    \"config_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\"\n",
      "  },\n",
      "  \"init\": {\n",
      "    \"read_source_data\": {\n",
      "      \"name\": \"read_disk_pandas\"\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"name\": \"define_mlp_simple\"\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"name\": \"get_keras_optimizer\"\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"name\": \"get_keras_loss\"\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"name\": \"compile_model\"\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"name\": \"fit\"\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"names\": [\n",
      "        \"save_hdf5\",\n",
      "        \"save_tensorflow_serving_predict_signature_def\"\n",
      "      ]\n",
      "    },\n",
      "    \"copy_from_local_to_remote\": {\n",
      "      \"name\": \"copy_from_disk_to_disk\"\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"name\": \"evaluate\"\n",
      "    },\n",
      "    \"callbacks\": [\n",
      "      {\n",
      "        \"name\": \"early_stopping\",\n",
      "        \"params\": {\n",
      "          \"patience\": 5,\n",
      "          \"monitor\": \"val_loss\",\n",
      "          \"min_delta\": 0.001\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"model_checkpoint\",\n",
      "        \"params\": {\n",
      "          \"filepath\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/model_checkpoint/last_best_model.h5\",\n",
      "          \"save_best_only\": true\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"predict\": {\n",
      "      \"name\": \"predict\"\n",
      "    },\n",
      "    \"custom_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_auc\",\n",
      "        \"evaluate_numpy_micro_auc\"\n",
      "      ]\n",
      "    },\n",
      "    \"custom_label_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_accuracy\",\n",
      "        \"evaluate_numpy_confusion_matrix\"\n",
      "      ]\n",
      "    },\n",
      "    \"store_prediction_artifact_locally\": {\n",
      "      \"name\": \"store_pandas_pickle\"\n",
      "    },\n",
      "    \"store_artifact_locally\": {\n",
      "      \"name\": \"store_dict_json\"\n",
      "    }\n",
      "  },\n",
      "  \"exec\": {\n",
      "    \"read_source_data\": {\n",
      "      \"params\": {\n",
      "        \"train_params\": {\n",
      "          \"path\": \"./example_data/array_123/train.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"valid_params\": {\n",
      "          \"path\": \"./example_data/array_123/valid.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        },\n",
      "        \"test_params\": {\n",
      "          \"path\": \"./example_data/array_123/test.csv\",\n",
      "          \"input_format\": \".csv\",\n",
      "          \"full_data_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\",\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\",\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ],\n",
      "          \"index_columns\": [\n",
      "            \"ID\",\n",
      "            \"ID2\"\n",
      "          ],\n",
      "          \"features_columns\": [\n",
      "            \"field1_num\",\n",
      "            \"field2_num\",\n",
      "            \"field3_num\"\n",
      "          ],\n",
      "          \"targets_columns\": [\n",
      "            \"field4_target\",\n",
      "            \"field5_target\",\n",
      "            \"field6_target\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"define_model\": {\n",
      "      \"params\": {\n",
      "        \"nb_classes\": 3,\n",
      "        \"nb_features\": 3,\n",
      "        \"dense_activation\": \"relu\",\n",
      "        \"final_activation\": \"softmax\"\n",
      "      }\n",
      "    },\n",
      "    \"get_optimizer\": {\n",
      "      \"params\": {\n",
      "        \"optimizer_name\": \"adam\",\n",
      "        \"optimizer_params\": {\n",
      "          \"lr\": 0.0001\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"params\": {\n",
      "        \"loss_name\": \"categorical_crossentropy\"\n",
      "      }\n",
      "    },\n",
      "    \"compile_model\": {\n",
      "      \"params\": {\n",
      "        \"metrics\": [\n",
      "          \"acc\"\n",
      "        ],\n",
      "        \"weighted_metrics\": null,\n",
      "        \"loss_weights\": null,\n",
      "        \"sample_weight_mode\": null,\n",
      "        \"target_tensors\": null\n",
      "      }\n",
      "    },\n",
      "    \"fit\": {\n",
      "      \"params\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"epochs\": 10\n",
      "      },\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"train\",\n",
      "          \"valid\",\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"transform_then_slice\": true,\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"full_data_wrapper_params\": {},\n",
      "          \"data_wrapper_names\": [\n",
      "            \"features\",\n",
      "            \"targets\",\n",
      "            \"index\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"predict\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_model\": {\n",
      "      \"save_hdf5\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__hdf5\",\n",
      "        \"extension\": \".h5\",\n",
      "        \"overwrite_remote\": true\n",
      "      },\n",
      "      \"save_tensorflow_serving_predict_signature_def\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "        \"temp_base_dir\": \"c:/tf_serving/_tmp_model/test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "        \"extension\": \".zip\",\n",
      "        \"overwrite_remote\": true,\n",
      "        \"do_save_labels_txt\": true,\n",
      "        \"input_name\": \"input\",\n",
      "        \"output_name\": \"output\",\n",
      "        \"labels_list\": [\n",
      "          \"cat\",\n",
      "          \"dog\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"evaluate_custom_metrics\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"evaluate_custom_label_metrics\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_session\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"filename\": \"session\"\n",
      "      }\n",
      "    },\n",
      "    \"save_session_artifacts\": {\n",
      "      \"artifacts\": [\n",
      "        {\n",
      "          \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\",\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "        },\n",
      "        {\n",
      "          \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"save_formatted_config\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "        \"filename\": \"config_formatted\"\n",
      "      }\n",
      "    },\n",
      "    \"prepare_predictions_for_storage\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"pandas\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"predictions\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"predictions\",\n",
      "          \"new_data_wrapper_name\": \"predictions_for_storage\"\n",
      "        },\n",
      "        \"targets\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"targets\",\n",
      "          \"new_data_wrapper_name\": \"targets_for_storage\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_predictions\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__predictions\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_targets\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"targets_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "            \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__targets\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__keras_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_label_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "          \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_label_metrics\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "}\n"
     ]
    }
   ],
   "source": [
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": [
    "for artifact_dict in config[\"exec\"][\"save_session_artifacts\"][\"artifacts\"]:\n",
    "    \n",
    "    artifact_dir=os.path.dirname(artifact_dict[\"artifact_path\"]) \n",
    "    artifact_filename=os.path.basename(artifact_dict[\"artifact_path\"])\n",
    "    \n",
    "    # save to local artifact store\n",
    "    common_containers.ArtifactCopiers.copy_from_disk_to_disk(\n",
    "        source_dir=artifact_dir,\n",
    "        target_dir=artifact_dict[\"local_dir\"],\n",
    "        filename=artifact_filename,\n",
    "        overwrite=False,\n",
    "        delete_source=False)\n",
    "\n",
    "    # copy to remote artifact store\n",
    "    copy_from_local_to_remote(source_dir=artifact_dict[\"local_dir\"],\n",
    "                              target_dir=artifact_dict[\"remote_dir\"],\n",
    "                              filename=artifact_filename,\n",
    "                              overwrite=False,\n",
    "                              delete_source=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session artifacts stored with following parameters\n",
      "{\n",
      "  \"artifacts\": [\n",
      "    {\n",
      "      \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\config/fit_config_array.json\",\n",
      "      \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "      \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "    },\n",
      "    {\n",
      "      \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml-github\\\\examples\\\\keras\\\\fit.ipynb\",\n",
      "      \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/session\",\n",
      "      \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/session\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session artifacts stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_session_artifacts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\karl.schriek\\appdata\\local\\conda\\conda\\envs\\mercury_ml_training\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: c:/tf_serving/_tmp_model/test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\\1\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "for model_format, save_model in save_model_dict.items():\n",
    "    \n",
    "    tasks.store_model(save_model=save_model,\n",
    "                      model=model,\n",
    "                      copy_from_local_to_remote = copy_from_local_to_remote,\n",
    "                      **config[\"exec\"][\"save_model\"][model_format]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with following paramters: \n",
      "\n",
      "{\n",
      "  \"save_hdf5\": {\n",
      "    \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "    \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "    \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__hdf5\",\n",
      "    \"extension\": \".h5\",\n",
      "    \"overwrite_remote\": true\n",
      "  },\n",
      "  \"save_tensorflow_serving_predict_signature_def\": {\n",
      "    \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "    \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/models\",\n",
      "    \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "    \"temp_base_dir\": \"c:/tf_serving/_tmp_model/test_array__b02a1c74a09642639b46f7d0457d5e2e__tf_serving_predict\",\n",
      "    \"extension\": \".zip\",\n",
      "    \"overwrite_remote\": true,\n",
      "    \"do_save_labels_txt\": true,\n",
      "    \"input_name\": \"input\",\n",
      "    \"output_name\": \"output\",\n",
      "    \"labels_list\": [\n",
      "      \"cat\",\n",
      "      \"dog\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model saved with following paramters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "data_bunch_metrics = maybe_transform(data_bunch_fit, config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "train <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "valid <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "test <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 50us/step\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_metrics, data_set_name)\n",
    "    metrics[data_set_name] = evaluate(model, data_set, **config[\"exec\"][\"evaluate\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"loss\": 1.822854995727539,\n",
      "    \"acc\": 0.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting metrics: \\n\")\n",
    "print_dict(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "data_bunch_predict = maybe_transform(data_bunch_metrics, config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))\n",
    "    \n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "train <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "valid <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n",
      "test <DataSet>\n",
      "  full_data <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  features <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"predict\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_predict, data_set_name)\n",
    "    data_set.predictions = predict(model=model, data_set=data_set, **config[\"exec\"][\"predict\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data predicted with following parameters: \n",
      "\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data predicted with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_custom_metrics = maybe_transform(data_bunch_predict, \n",
    "                                            config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_set_names\": [\n",
      "    \"test\"\n",
      "  ],\n",
      "  \"params\": {\n",
      "    \"transform_to\": \"numpy\",\n",
      "    \"data_wrapper_params\": {\n",
      "      \"predictions\": {},\n",
      "      \"index\": {},\n",
      "      \"targets\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_custom_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [],
   "source": [
    "custom_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_metrics[data_set_name]  = tasks.evaluate_metrics(data_set, custom_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "lines_to_next_cell": 2.0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting custom metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"evaluate_numpy_auc\": 0.26111111111111107,\n",
      "    \"evaluate_numpy_micro_auc\": 0.53\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting custom metrics: \\n\")\n",
    "print_dict(custom_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom label metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_label_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_label_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_label_metrics[data_set_name] = tasks.evaluate_label_metrics(data_set, custom_label_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting custom label metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"Accuracy\": {\n",
      "      \"field4_target\": 0.6,\n",
      "      \"field5_target\": 0.8,\n",
      "      \"field6_target\": 0.7\n",
      "    },\n",
      "    \"ConfMat_Count_field4_target\": {\n",
      "      \"field4_target\": 10,\n",
      "      \"field5_target\": 4,\n",
      "      \"field6_target\": 6\n",
      "    },\n",
      "    \"ConfMat_Rate_field4_target\": {\n",
      "      \"field4_target\": 1.0,\n",
      "      \"field5_target\": 1.0,\n",
      "      \"field6_target\": 1.0\n",
      "    },\n",
      "    \"ConfMat_Count_field5_target\": {\n",
      "      \"field4_target\": 0,\n",
      "      \"field5_target\": 0,\n",
      "      \"field6_target\": 0\n",
      "    },\n",
      "    \"ConfMat_Rate_field5_target\": {\n",
      "      \"field4_target\": 0.0,\n",
      "      \"field5_target\": 0.0,\n",
      "      \"field6_target\": 0.0\n",
      "    },\n",
      "    \"ConfMat_Count_field6_target\": {\n",
      "      \"field4_target\": 0,\n",
      "      \"field5_target\": 0,\n",
      "      \"field6_target\": 0\n",
      "    },\n",
      "    \"ConfMat_Rate_field6_target\": {\n",
      "      \"field4_target\": 0.0,\n",
      "      \"field5_target\": 0.0,\n",
      "      \"field6_target\": 0.0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting custom label metrics: \\n\")\n",
    "print_dict(custom_label_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom metrics saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "      \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "      \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_metrics\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_label_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_label_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom label metrics saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "      \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/metrics/test\",\n",
      "      \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__custom_label_metrics\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom label metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_label_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare predictions for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_preparation = maybe_transform(data_bunch_predict, \n",
    "                                                    config[\"exec\"][\"prepare_predictions_for_storage\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare predictions and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"prepare_predictions_for_storage\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_prediction_preparation, data_set_name)\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"predictions\"])\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test <DataSet>\n",
      "  predictions <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "  predictions_for_storage <PandasDataWrapper>\n",
      "  targets_for_storage <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_data_bunch(data_bunch_prediction_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_storage = maybe_transform(data_bunch_prediction_preparation, \n",
    "                                                config[\"exec\"][\"save_predictions\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "  predictions_for_storage <PandasDataWrapper>\n",
      "  targets_for_storage <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_predictions\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__predictions\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_targets\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"data_wrapper_name\": \"targets_for_storage\",\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "        \"remote_dir\": \"./example_results/remote/b02a1c74a09642639b46f7d0457d5e2e/predictions/test\",\n",
      "        \"filename\": \"test_array__b02a1c74a09642639b46f7d0457d5e2e__test__targets\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_targets\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
